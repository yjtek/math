{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivating Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In electrical signals, we know that $$\\text{Power}(t) = I(t)^2R = \\frac{V(t)^2}{R}$$\n",
    "- That is, power is proportional to signal squared!\n",
    "- We'll generalise this concept in this chapter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The power of a signal is defined as $$\\text{Power}_X(t) = X(t)^2$$\n",
    "- When signals are random, we typically report its expected power rather than absolute values\n",
    "\n",
    "- **Definition 55.1 (Expected Power)** The expected power of $\\{ X(t) \\}$ is defined as $$E[X(t)^2]$$\n",
    "    - Recall that autocorrelation function $R_X(s,t) = E[X(s)X(t)]$\n",
    "    - So the power is simply the special case of the autocorrelation function when $s=t$\n",
    "        - $$R_X(s,t) = E[X(s)X(t)] = E[X(t)^2] = \\text{Power}_X(t)$$\n",
    "\n",
    "- We usually only look at stationary processes when discussing power. The reason for this will be discussed in more detail in chapter 56, but for now just take for granted that all the power computations (and by extension, the autocorrelation computations) are for stationary processes\n",
    "    - So all in all, we will focus on (i) stationary processes, (ii) when $t=s$\n",
    "    - (i) is almost always true. (ii) is always true\n",
    "    $$\\begin{align}\n",
    "        R_X(s,t) &= R_X(t-s) \\\\ \n",
    "        &= R_X(\\tau) \\\\\n",
    "        &= R_X(0) \\\\\n",
    "        \\end{align}$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 55.1 (White Noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consider the white noise process $\\{ Z[n] \\}$ defined in Example 47.2, which consists of i.i.d. random variables with mean $\\mu = E[Z[n]]$ and variance $\\sigma^2 = Var[Z[n]]$. What is the expected power of this process $E[Z[n]^2]$?\n",
    "\n",
    "- The process is stationary with autocorrelation function \n",
    "$$\\begin{align} \n",
    "    R_Z[k] &= Cov_Z[m,n] + \\mu_m \\mu_n \\\\\n",
    "    &= \\sigma^2 \\delta[k] + \\mu^2 \\\\\n",
    "    &= \\sigma^2 + \\mu^2 & \\text{when } k = m-n = 0\n",
    "\\end{align}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 55.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consider the process $\\{ X(t) \\}$ from Example 53.5. This process is stationary, with autocorrelation function \n",
    "$$\\begin{align}\n",
    "    R_X(\\tau) &= E[X(t)^2] \\\\\n",
    "    &= Cov[X(t), X(t)] + \\mu_X^2 \\\\\n",
    "    &= 5e^{-3\\tau^2} + 4\n",
    "\\end{align}$$\n",
    "\n",
    "- Recall that \n",
    "    - The power is just the autocorrelation function evaluated at $s=t$\n",
    "    - $\\mu_s = \\mu_t = 2$\n",
    "    - $Cov[X(t), X(t)] = 5e^{-3\\tau^2} = 5 e^{-3 \\cdot 0^2} = 5$ \n",
    "        - This is because $s=t$, and so $\\tau = 0$\n",
    "    - Since this process is stationary, the autocorrelation function is \n",
    "\n",
    "$$ R_X(\\tau) = R_X(0) = 5e^{-3\\tau^2} + 4 = 5e^{-3 \\cdot 0^2} + 4 = 9 $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
