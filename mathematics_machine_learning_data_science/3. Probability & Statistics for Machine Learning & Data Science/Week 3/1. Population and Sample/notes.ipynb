{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Population $N$ is the entirety of your sample space, sample $n$ is a subset of it\n",
    "\n",
    "- Sample mean $\\bar{x}$ is going to have a distribution around the population mean $\\mu_X$\n",
    "    - The larger your sample size $n$, the more tightly your samples $\\bar{x}$ will cluster around $\\mu_X$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estimating population variance from sample variance is not quite the same as estimating the population mean from sample mean. We can prove it with a simple test below\n",
    "    - Let's suppose there is a fair 3 sided die, and let X be the population of observations is (1,2,3)\n",
    "        - $E[X] = 2$\n",
    "        - $Var[X] = \\frac{(1-2)^2 + (2-2)^2 + (3-2)^2}{3} = \\frac{2}{3}$\n",
    "    - We will take repeated samples of 2 rolls from this die, and try to estimate the population mean and variance from sample mean and variance\n",
    "    - Clearly, the usual variance formula applied to the 2 sample case gives the wrong estimate of $Var[X]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population Mean: 2.0 || Population Variance: 0.6666666666666666\n",
      "Sample Mean: 1.9973 || Sample Variance Wrong: 0.33325 || Sample Variance Right: 0.6665\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dice_outcomes = np.array([1,2,3])\n",
    "population_mean=np.mean(dice_outcomes)\n",
    "population_var=np.var(dice_outcomes)\n",
    "\n",
    "n = 10000\n",
    "roll_1 = [np.random.choice(dice_outcomes) for _ in range(n)]\n",
    "roll_2 = [np.random.choice(dice_outcomes) for _ in range(n)]\n",
    "sample_mean = np.mean([np.mean(np.array([x,y])) for x,y in zip(roll_1, roll_2)])\n",
    "sample_var_wrong = np.mean([((x - np.mean([x,y]))**2 + (y - np.mean([x,y]))**2)/2 for x,y in zip(roll_1, roll_2)])\n",
    "sample_var_right = np.mean([((x - np.mean([x,y]))**2 + (y - np.mean([x,y]))**2)/(2-1) for x,y in zip(roll_1, roll_2)])\n",
    "\n",
    "print(f'Population Mean: {population_mean} || Population Variance: {population_var}')\n",
    "print(f'Sample Mean: {sample_mean} || Sample Variance Wrong: {sample_var_wrong} || Sample Variance Right: {sample_var_right}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Law of large numbers\n",
    "    - if sample is randomly drawn, sample size is sufficiently large, independent observations, then $E[X] \\rightarrow \\mu_X$ as $n \\rightarrow \\infty$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Central limit theorem\n",
    "    - Regardless of the underlying distribution, with sufficiently large sample size $n$ from a population of finite variance, $\\mu_{\\bar{x}} \\rightarrow \\mu_X$ and $s_x^2 \\rightarrow \\sigma_X^2$\n",
    "    - Also, $\\mu_{\\bar{x}} \\sim N(\\mu_X, \\frac{\\sigma_X^2}{n})$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leetcode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
