{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 39: Fisher’s exact test for consistency in a 2 × 2 table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You have a 2x2 table\n",
    "- The columns are made up of 2 classes\n",
    "- The rows are made up of 2 samples\n",
    "- Is there evidence that the two samples are drawn from the same population?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The classification is dichotomous\n",
    "- The elements originate from 2 sources\n",
    "- Number of elements are small, expected frequencies are less than 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypergeometric Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The derivation of this test is actually from simple sampling without replacement (i.e. Hypergeometric Distribution)\n",
    "\n",
    "- Imagine you have a bag with 7 red balls, and 6 green balls\n",
    "\n",
    "- I claim that I have special powers. Without looking into the bag, I am able sense whether the ball is red or green. \n",
    "\n",
    "- To test this claim, you ask that I draw 7 balls from this bag, drawing only red balls\n",
    "\n",
    "- Of this 7, I drew 6 red and 1 green ball\n",
    "\n",
    "- Let's put this result into a 2x2 table\n",
    "\n",
    "| | Red | Green | Row Total |\n",
    "| - | - | - | - |\n",
    "| Sampled | 6 | 1 | 7 |\n",
    "| Not Sampled | 1 | 5 | 6 | \n",
    "| Column Total | 7 | 6 | n = 13 |\n",
    "\n",
    "- Does this confirm that I have special powers? \n",
    "\n",
    "- Let $k$ be the number of red balls I manage to draw\n",
    "\n",
    "- Let's assume that we do not. The probability that I get this result by randomly picking balls is simply the probality that $k = 6$ \n",
    "\n",
    "- We can compute the probability that $k=6$ by counting the number of ways to get 6 reds and 1 green out of the total number of ways to draw 7 balls randomly\n",
    "$$\\begin{aligned}\n",
    "    P(k=6) &= \\frac{\\binom{7}{6} \\cdot \\binom{6}{1}}{\\binom{13}{7}} \\\\\n",
    "    &= \\frac{7 \\cdot 6}{1716} \\\\\n",
    "    &= 0.02448\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deriving the p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ok, so now we know the probability of such a scenario happening by chance, or the probability mass function (PMF) of this outcome\n",
    "\n",
    "- However, we don't just want to know this; we want the p-value. That is; what is the probability of seeing something equal to or more extreme than this value\n",
    "\n",
    "- Why do we want the p-value? Because to conclude that something is rare, it's not enough to know what the absolute probability is. It's more important to know where it stands among all possible outcomes! (i.e. how extreme is this value)\n",
    "    - For example, 2.4% may seem small, but what if that 2.4% is actually in the middle of the distribution? i.e. 50% of all possible outcomes are on the right of the 2.4%. \n",
    "    - In that case, it's obviously not an extreme value at all, though it is seemingly \"rare\" to see something like this\n",
    "\n",
    "- So how do we compute the p-value? p-value is simply the sum of probabilities that are more extreme than $k=6$. \n",
    "\n",
    "- Practically speaking, we find all outcomes that have a lower probability than $k=6$ and sum them up\n",
    "    - In the one-tail test, the alternative hypothesis is: is the proportion of successes (reds) larger in my sampled class compared to my unsampled class. Concretely:\n",
    "    $$\\begin{aligned}\n",
    "        \\sum p &= P(k=6) + P(k=7) \\\\\n",
    "        &= \\frac{\\binom{7}{6} \\cdot \\binom{6}{1}}{\\binom{13}{7}} + \\frac{\\binom{7}{7} \\cdot \\binom{6}{0}}{\\binom{13}{7}} \\\\\n",
    "        &= 0.0245 + 0.000583 \\\\\n",
    "        &= 0.02505\n",
    "    \\end{aligned}$$\n",
    "\n",
    "    - In the two-tail test, the alternative hypothesis is: is the proportion of successes (reds) **different** in my sampled class compared to my unsampled class \n",
    "        - Using the same logic as the one tail test, let's compute everything that is \"rarer\" than the $k=6$ case\n",
    "        - $P(k=6) = \\frac{\\binom{7}{6} \\cdot \\binom{6}{1}}{\\binom{13}{7}} = 0.0245$\n",
    "        - $P(k=7) = \\frac{\\binom{7}{7} \\cdot \\binom{6}{0}}{\\binom{13}{7}} = 0.000583$\n",
    "        - $P(k=1) = \\frac{\\binom{7}{1} \\cdot \\binom{6}{6}}{\\binom{13}{7}} = 0.00408$\n",
    "        - $P(k=2) = \\frac{\\binom{7}{2} \\cdot \\binom{6}{5}}{\\binom{13}{7}} = 0.0734$\n",
    "        - The cases that are rarer that $P(k=6)$ are $P(k=7)$ and $P(k=1)$\n",
    "        - Therefore, p-value is $0.0245 + 0.000583 + 0.00408 = 0.0292$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In fact, the process computing the p-value above is exactly the test-statistic for Fisher's Exact test!\n",
    "\n",
    "- In general, let's suppose we have a 2x2 table below:\n",
    "\n",
    "| | Class 1A | Class 1B | Total |\n",
    "| - | - | - | - |\n",
    "| Class 2A | a | b | a + b |\n",
    "| Class 2B | c | d | c + d |\n",
    "| Total | a+c | b+d | n=a+b+c+d |\n",
    "\n",
    "- The test statistic is \n",
    "$$\\begin{aligned}\n",
    "    \\sum p &= \\sum \\frac{\\frac{(a+c)!}{a_i! c_i!} \\frac{(b+d)!}{b_i! d_i!}}{\\frac{n!}{(a+b)!(c+d)!}} \\\\\n",
    "    &= \\sum \\frac{(a+b)!(c+d)!(a+c)!(b+d)!}{a_i! c_i!b_i! d_i! n!} \\\\\n",
    "    &= \\frac{(a+b)!(c+d)!(a+c)!(b+d)!}{n!} \\sum \\frac{1}{a_i! c_i!b_i! d_i!} \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "- The confusing portion of this notation is the subscript $i$; in this case, we are summing across all $i$ such that the PMF of the specific case is lower than the PMF of the hypothesis\n",
    "\n",
    "- Since the test statistic is a sum of PMFs, it is bounded between 0 and 1\n",
    "\n",
    "- Therefore, the critical value is simply $\\alpha = 0.05$ or whatever level of confidence you want. No need for additional look up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Derivation from first principles above, no need for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "100_statistical_tests_-_gopal_kanji-JR8uAaSp-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
