{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivating Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lesson 18, we found the joint distribution of X, the number of bets that Xavier wins, and Y, the number of bets that Yolanda wins. If all we have is the joint distribution of X and Y, can we recover the distribution of X alone?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's try to solve the motivating example using the table we previously generated in section 18\n",
    "\n",
    "$\\begin{array}{rr|cccc}\n",
    " & 0 & 0.040386\t& 0.072695 & 0.032713 & 0.000000 & 0.000000 & 0.000000 \\\\\n",
    "X & 1 & 0.000000 & 0.109042 & 0.196276 & 0.088324 & 0.000000 & 0.000000 \\\\\n",
    " & 2 & 0.000000 & 0.000000 & 0.098138 & 0.176649 & 0.079492 & 0.000000 \\\\\n",
    " & 3 & 0.000000 & 0.000000 & 0.000000 & 0.029441 & 0.052995 & 0.023848 \\\\\n",
    "\\hline\n",
    "& & 0 & 1 & 2 & 3 & 4 & 5 \\\\\n",
    "& & & & & Y &\n",
    "\\end{array}$\n",
    "\n",
    "- Imagine that all we have is this table of joint PMFs $f(X,Y)$. What if I want to know $P(X = 2)$?\n",
    "    - This is represented by the row where X=2\n",
    "    - Then intuitively, $P(X = 2)$ is simply the sum of the row\n",
    "    - $P(X = 2) = 0.098138 + 0.176649 + 0.079492 = 0.3542$\n",
    "    - From the binomial fromula: $f(2) = \\binom{3}{2} \\frac{18^2}{38^2} \\frac{20}{38} = 0.3543$\n",
    "        - Answers match!!\n",
    "\n",
    "- Generalising this idea, recall from section 10 that $P(X=x) = \\sum_y f(x,y)$\n",
    "    - That is, the probability that X takes on the value x is simply the sum of the joint probabilities across all values of $y$\n",
    "\n",
    "- This idea of recovering $P(X=x) = f(x)$ from $f(x,y)$ by taking the summation of joint PMF is used quite frequently\n",
    "    - As such, we give it a special name\n",
    "    - We call this the **marginal distribution** of X\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definition 19.1:  The marginal p.m.f. of X refers to the p.m.f. of X when it is calculated from the joint p.m.f. of X and Y. Specifically, the marginal p.m.f. $f_{X}$ can be calculated from the joint p.m.f. $f(x,y)$ as follows:\n",
    "    - $f_{X}(x) = P(X=x) = \\sum_y f(x,y)$\n",
    "    - $f_{Y}(y) = P(Y=y) = \\sum_x f(x,y)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Theorem 19.1: (Joint Distribution of Independent Random Variables) If X and Y are independent, then $f(x,y) = f_X(x) \\cdot f_Y(y)$\n",
    "    - This is equivalent to saying $f(x,y) = P(X=x) \\cdot P(Y=y|X) = P(X=x) \\cdot P(Y=y)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 19.1 (follows from example 18.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In Example 18.3, we found that the joint distribution of the number of eggs N and the number of chicks X was\n",
    "$$\n",
    "f(X,N) = \\left \\{ \\begin{matrix}\n",
    "    e^{-\\mu} \\frac{\\mu^{N}}{N!} \\cdot \\frac{N!}{x! (N-x)!} p^{x} (1-p)^{N-x} & 0 \\leq x \\leq n \\lt \\inf \\\\\n",
    "    0 & \\text{otherwise}\n",
    "\\end{matrix} \\right .\n",
    "$$\n",
    "\n",
    "- What is the marginal distribution of the number of chicks X?\n",
    "    - To recover $X$, we need to sum all the joint probabilities $f(X,N)$ over all values of $N$\n",
    "    - $\\begin{align}\n",
    "        f_X(x) &= \\sum_{N=x}^{N = \\inf}f(N,X) \\\\\n",
    "        &= \\sum_{N=x}^{N = \\inf} e^{-\\mu} \\frac{\\mu^{N}}{N!} \\cdot \\frac{N!}{x! (N-x)!} p^{x} (1-p)^{N-x} \\\\\n",
    "        &= \\sum_{N=x}^{N = \\inf} e^{-\\mu} \\frac{(\\mu p)^{x}}{x!} \\cdot \\frac{(\\mu \\cdot (1-p))^{N-x}}{(N-x)!} \\\\\n",
    "        &= e^{-\\mu} \\frac{(\\mu p)^{x}}{x!} \\sum_{N=x}^{N = \\inf} \\frac{(\\mu \\cdot (1-p))^{N-x}}{(N-x)!} \\\\\n",
    "        &= e^{-\\mu} \\frac{(\\mu p)^{x}}{x!} \\sum_{N=x}^{N = \\inf} \\frac{(\\nu)^{m}}{m!} & \\nu=\\mu(1-p), m=n-x\\\\\n",
    "        &= e^{-\\mu} \\frac{(\\mu p)^{x}}{x!} e^{\\nu} & \\sum_{m=0}^{\\inf} e^{-\\nu} \\frac{\\nu^m}{m!} = 1 \\\\\n",
    "        &= e^{-\\mu + \\nu} \\frac{(\\mu p)^{x}}{x!} \\\\\n",
    "        &= e^{-\\mu + \\mu(1-p)} \\frac{(\\mu p)^{x}}{x!} \\\\\n",
    "        &= e^{-\\mu p} \\frac{(\\mu p)^{x}}{x!} \\\\\n",
    "    \\end{align}$\n",
    "    - This is just the poisson PMF with mean $\\mu p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leetcode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
