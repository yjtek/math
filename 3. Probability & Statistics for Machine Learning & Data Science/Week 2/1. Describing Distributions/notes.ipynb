{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Central tendency of distribution X\n",
    "    - Mean(X) == E(X)\n",
    "    - Median X: Middle of X\n",
    "    - Mode X: Most common value X\n",
    "    - Right skew X: Mean > Median\n",
    "    - Left skew X: Mean < Median\n",
    "\n",
    "- Expectation of a random variable is just the mean, but what if you want the expectation of a *function* of a random variable?\n",
    "    - if $E[X] = x_1p_1(x_1) + x_2p_2(x_2) + x_3p_3(x_3)$\n",
    "    - then $E[f(X)] = f(x_1)p_1(x_1) + f(x_2)p_2(x_2) + f(x_3)p_3(x_3)$\n",
    "    - e.g. Let value from 1 roll of dice be X\n",
    "        - $E[X] = 1 * \\frac{1}{6} + 2 * \\frac{1}{6} + 3 * \\frac{1}{6} + 4 * \\frac{1}{6} + 5 * \\frac{1}{6} + 6 * \\frac{1}{6} = 3.5$\n",
    "        - $E[X^2] = 1^2 * \\frac{1}{6} + 2^2 * \\frac{1}{6} + 3^2 * \\frac{1}{6} + 4^2 * \\frac{1}{6} + 5^2 * \\frac{1}{6} + 6^2 * \\frac{1}{6} = \\frac{91}{6}$\n",
    "\n",
    "- Sum of expectations: $E[X_1 + X_2] = E[X_1] + E[X_2]$\n",
    "    - e.g. Let's suppose you have 3 people assigned an index number each (1,2,3). You don't know what each of their numbers are, so you have to guess. Let $X$ be the number of people for whom you guess the right number. What is $E[X]$?\n",
    "        - We know that $E[X] = E[X_1] + E[X_2] + E[X_3]$, where $X_n$ is an indicator that is 1 when the guessed number is right, and 0 if it is wrong\n",
    "        - $E[X_i]$ is 1/3 for all values of $i$, because you are randomly guessing\n",
    "        - So $E[X] = 1$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare 2 coin flip games: \n",
    "    - If heads, you win $1, tails, you lose $1\n",
    "    - If heads, you win $100, tails, you lose $100\n",
    "    - Expected value is 0 for both, but variance very different\n",
    "        - $\\frac{(1-0)^2 + (1-0)^2} {2} = 1$\n",
    "        - $\\frac{(100-0)^2 + (100-0)^2} {2} = 10000$\n",
    "\n",
    "- Variance\n",
    "$$\\begin{align}\n",
    "    Var(X) &= E[(X - \\mu)^2] \\\\\n",
    "    &= E[X^2 - 2(X)\\mu + \\mu^2] \\\\\n",
    "    &= E[X^2] - 2 \\cdot \\mu \\cdot E(X) + E(\\mu^2) \\\\\n",
    "    &= E[X^2] - 2 \\cdot E(X) \\cdot \\mu + \\mu^2 \\\\\n",
    "    &= E[X^2] - 2 \\cdot (E(X))^2 + (E[X])^2 \\\\ \n",
    "    &= E[X^2] - (E(X))^2\n",
    "\\end{align}$$\n",
    "\n",
    "- Standard Deviation\n",
    "    - Square root of variance, to preserve the units\n",
    "    - i.e. if X is measured in meters, Var(X) will be in meters squared, and so it is not directly comparable to X\n",
    "    - Std Dev preserves this"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum of gaussians"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assume $X \\sim N(\\mu_x, \\sigma_x^2)$, $Y \\sim N(\\mu_y, \\sigma_y^2)$\n",
    "- **If and only if** X and Y are independent, then $X+Y \\sum N(\\mu_x + \\mu_y, \\sigma_x^2 + \\sigma_y^2)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For many applications of ML, standardising a variable makes it less prone to computational issues\n",
    "- Let Z be the standardised random variable from X\n",
    "    - Usual way is $Z = \\frac{X - \\mu}{\\sigma}$\n",
    "- Proof that $E[Z] = 0$\n",
    "    - $\\begin{align}\n",
    "        E[Z] &= E[X - \\mu] \\\\\n",
    "        &= E[X] - E[\\mu] \\\\\n",
    "        &= E[X] - E[X] \\\\\n",
    "        &= 0\n",
    "    \\end{align}$\n",
    "- Proof that $Var(Z) = 1$\n",
    "    - $\\begin{align}\n",
    "        Var(Z) &= Var(\\frac{X - \\mu}{\\sigma}) \\\\\n",
    "        &= Var(\\frac{X}{\\sigma}) - Var(\\frac{\\mu}{\\sigma}) \\\\\n",
    "        &= Var(\\frac{X}{\\sigma}) \\\\\n",
    "        &= Var(\\frac{X}{\\sigma}) \\\\\n",
    "        &= \\frac{1}{\\sigma^2}Var(X)\n",
    "    \\end{align}$\n",
    "    - $\\begin{align}\n",
    "        std(Z) &= \\sqrt{\\frac{1}{\\sigma^2}Var(X)} \\\\\n",
    "        &= \\frac{1}{\\sigma} std(X) \\\\\n",
    "        &= \\frac{\\sigma}{\\sigma} \\\\\n",
    "        &= 1\n",
    "    \\end{align}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness/Kurtosis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Skewness: 3rd moment\n",
    "    - Definition: $E[(\\frac{(X - \\mu)}{\\sigma})^3]$\n",
    "    - If skewness > 0, right skew (positive skew)\n",
    "    - If skewness < 0, right skew (negative skew)\n",
    "    - If skewness == 0, no skew\n",
    "- E[X^4]: Kurtosis\n",
    "    - Definition: $E[(\\frac{(X - \\mu)}{\\sigma})^4]$\n",
    "    - If kurtosis is large, thick tails in distribution\n",
    "    - If kurtosis is small, thin tails in distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel density estimation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When we plot a histogram for a given set of values, it often is not smooth. This is because, if we define some set of bins, then the bins are typically discontinuous\n",
    "- To solve this, we can apply a **kernel** to smooth out the bins\n",
    "    1. On the X-axis, plot a vertical line wherever you have an observed value\n",
    "    2. Assume some distribution (a kernel) around the vertical line where you observe the point (use Gaussian for convenience)\n",
    "    3. Sum all the densities and multiply by $1/n$, where $n$ is the number of observations you have\n",
    "    4. This $1/n$ will give a value of 1 under the kernel density estimate"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
