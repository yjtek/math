{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Suppose we generate a random length L (in inches) from the p.m.f. below and draw a square with that sidelength. Calculate $E[L]^2$ and $E[L^2]$. Are they the same? Which one represents the expected area of the square we drew?\n",
    "\n",
    "| $\\imath$ | 1 | 2 | 3 |\n",
    "| --- | --- | --- | --- |\n",
    "f($\\imath $) | 0.2 | 0.5 | 0.3 |\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $E[L] = (0.2 + 1 + 0.9)/3 = 0.7$\n",
    "- Hence, $E[L]^2 = 0.7^2 = 0.49$\n",
    "- $E[L^2] = (0.2*1 + 0.5*4 + 0.3*9)/3 = 1.63$\n",
    "\n",
    "- Not the same, expected area of square drawn is 1.6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Let X be a $\\text{Poisson}(\\mu)$ random variable. Calculate $E[X(X-1)]$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $X = e^{-\\mu} \\frac{\\mu^x}{x!}$\n",
    "\n",
    "$$\\begin{align}\n",
    "    E[X(X-1)] &= \\sum_{x} f_X(x) \\cdot g(x) \\\\\n",
    "    &= \\sum_{x} e^{-\\mu} \\frac{\\mu^x}{x!} \\cdot x(x-1) \\\\\n",
    "    &= \\sum_{x} e^{-\\mu} \\frac{\\mu^{x-2}}{(x-2)!} \\cdot \\mu^2 \\\\\n",
    "    &= \\mu^2\n",
    "\\end{align}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Let X be a $\\text{Geometric}(p)$ random variable. Let t be a constant. Calculate $M(t) = E[e^{tX}]$ as a function of t. Statisticians call this the moment generating function of X, while engineers may recognize this function as the Laplace transform of the p.m.f. of X."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $X = (1-p)^{n-1} p$\n",
    "- Note that $\\sum_{x=0}^{\\inf} q^x = \\frac{q}{1-q}$\n",
    "    - Let $S_n = 1 + q + q^2 + ... q^n$\n",
    "    - Then $(1-q)S_n = (1-q)(1 + q + q^2 + ... + q^n) = 1-q^{n+1}$\n",
    "    - Then $S_n = \\frac{1-q^{n+1}}{1-q}$\n",
    "    - and $S_n = \\frac{1}{1-q}$ as $n \\rightarrow \\inf$\n",
    "    - So $\\sum_{x=0}^{\\inf} q^x = \\frac{1}{1-q}$\n",
    "\n",
    "$$\\begin{align}\n",
    "    E[e^{tX}] &= \\sum_{x=1}^{\\inf} f_X(x) \\cdot g(x) \\\\\n",
    "    &= \\sum_{x=0}^{\\inf} (1-p)^{x} p \\cdot e^{tx} \\\\\n",
    "    &= p \\sum_{x=0}^{\\inf} (1-p)^{x} \\cdot e^{tx} \\\\\n",
    "    &= p \\sum_{x=0}^{\\inf} (e^{t} \\cdot (1-p))^{x} \\\\\n",
    "    &= \\frac{p}{1 - (e^{t} \\cdot (1-p))}\n",
    "\\end{align}$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Another resolution to the St. Petersburg Paradox is to consider expected utility U rather than expected wealth W. (“Utility” is the term that economists use for “happiness”.) Because of diminishing marginal utility, the first million dollars is worth more than the next million dollars. One way to model diminishing marginal utility is to assume that $U = log(W)$. Show that the expected utility of the St. Petersburg game is finite, even though the expected winnings is infinite.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We established previously that $W = 2^{N-1}$\n",
    "- We also established that $N \\sim \\text{Geom}(0.5)$\n",
    "- So PMF of N is: \n",
    "    - $f_N(n) = 0.5^{n-1} 0.5 = 0.5^n$\n",
    "\n",
    "- Applying LOTUS:\n",
    "    - $\\begin{align}\n",
    "        E[W] &= E[2^{n-1}] \\\\\n",
    "        &= \\sum_{n=1}^{\\inf} 2^{n-1} 0.5^n \\\\\n",
    "        &= \\sum_{n=1}^{inf} \\frac{1}{2}\n",
    "    \\end{align}$\n",
    "\n",
    "- We do the same thing, but applying one more transformation:\n",
    "    - $\\begin{align}\n",
    "        E[U] &= E[log(W)] \\\\\n",
    "        &= E[log(2^{n-1})] \\\\\n",
    "        &= \\sum_{n=1}^{\\inf} log(2^{n-1}) 0.5^n \\\\\n",
    "    \\end{align}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Let X be a $\\text{Hypergeom}(n, N_1, N_0)$ random variable. Calculate E[X(X-1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $X = \\frac{\\binom{N_1}{x} \\binom{N_0}{n-x}}{\\binom{N}{n}}$\n",
    "\n",
    "$$\\begin{align}\n",
    "    E[X(X-1)] &= \\sum_x g(x) f_X(x) \\\\\n",
    "    &= \\sum_x x(x-1) \\frac{\\binom{N_1}{x} \\binom{N_0}{n-x}}{\\binom{N}{n}} \\\\\n",
    "    &= \\sum_x x(x-1) \\frac{\\frac{N_1!}{(x)!(N_1 - x)!} \\frac{N_0!}{(n-x)!(N_0 - n + x)!}}{\\frac{N!}{n!(N-n)!}} \\\\\n",
    "    &= \\sum_x \\frac{N_1(N_1-1) \\frac{(N_1 - 2)!}{(x-2)!(N_1 - x)!} \\frac{N_0!}{(n-x)!(N_0 - n + x)!}}{\\frac{N(N-1)(N-2)!}{n(n-1)(n-2)!(N-n)!}} \\\\\n",
    "    &= \\frac{N_1(N_1-1)}{\\frac{N(N-1)}{n(n-1)}} \\sum_x \\frac{\\frac{(N_1 - 2)!}{(x-2)!(N_1 - x)!} \\frac{N_0!}{(n-x)!(N_0 - n + x)!}}{\\frac{(N-2)!}{(n-2)!(N-n)!}} \\\\\n",
    "    &= N_1(N_1-1) \\cdot \\frac{n(n-1)}{N(N-1)} \\\\\n",
    "    &= \\frac{N_1}{N} \\cdot \\frac{N_1-1}{N-1} \\cdot n(n-1) \\\\\n",
    "\\end{align}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Let X be a $\\text{Poisson}(\\mu)$ random variable for $0 < \\mu < 1$. Calculate E[X!]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $X = e^{-\\mu} \\frac{\\mu^x}{x!}$\n",
    "\n",
    "$$\\begin{align}\n",
    "    E[X!] &= \\sum_x g(x) f_X(x) \\\\\n",
    "    &= \\sum_x x! \\cdot e^{-\\mu} \\frac{\\mu^x}{x!} \\\\\n",
    "    &= e^{-\\mu} \\sum_x \\mu^x \\\\\n",
    "    &= e^{-\\mu} \\frac{1}{1 - \\mu^x} & \\sum_{k=0}^{n} q^k = \\frac{1}{1-q} \\text{ as n tends to infinity}\\\\\n",
    "    &= \\frac{e^{-\\mu}}{1 - \\mu^x} \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "- If step 4 is confusing, see note in question 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Let X be a $\\text{NegativeBinomial}(r, p)$ random variable. Calculate E[(X+1)X]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $X = \\binom{x-1}{r-1} p^{r} (1-p)^{x-r}$\n",
    "\n",
    "$$\\begin{align}\n",
    "    E[(X+1)X] &= \\sum_{x} x(x+1) \\binom{x-1}{r-1} p^{r} (1-p)^{x-r} \\\\\n",
    "    &= \\sum_{x} x(x+1) \\frac{(x-1)!}{(r-1)! (x-r)!} p^{r} (1-p)^{x-r} \\\\\n",
    "    &= \\frac{r(r+1)}{p^2} \\sum_{x} \\frac{(x+1)!}{(r+1)! (x-r)!} p^{r+2} (1-p)^{x-r} \\\\\n",
    "    &= \\frac{r(r+1)}{p^2} \n",
    "\\end{align}$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
