{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definition 52.1 (Autocovariance Function)** The autocovariance $C_X(s,t)$ of random process $\\{ X(t) \\}$ is a function of two times $s$ and $t$, and is also known as the **covariance function**. This specifies the covariance between the value of the process at time $s$ and time $t$ \n",
    "    - $C_{X}(s,t) = Cov[X(s), X(t)]$ for continuous time process \n",
    "    - $ C_{X}[m,n] = Cov[X[m], X[n]]$ for discrete time process  \n",
    "\n",
    "- Notice that the variance function can be obtained from the autocovariance function\n",
    "    - $ V(t) = Cov[X(t), X(t)] = C_{X}(t, t) $\n",
    "\n",
    "- You can think of the autocovariance function this way\n",
    "    - Imagine have some stochastic process that is a random walk $\\{ X(t) \\}$\n",
    "    - We previously said that the mean function is just the expectation of the process at time $t$ across many instantiations of the stochastic process, i.e. $E[X(t)]$ \n",
    "    - We previously said that the variance function is just the variance of the process at time $t$ across many instantiations of the stochastic process, i.e. $Var[X(t)]$\n",
    "    - In this case, the autocovariance $C_X(s,t)$ measures the covariance of the values at $s$ and $t$ across many instantiations of the stochastic process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 52.1 (Random Amplitude Process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consider the random amplitude process $ X(t) = A \\cos (2 \\pi ft) $ introduced in Example 48.1. What is the autocariance function $C_X(s, t)$?\n",
    "    - $A \\sim \\text{Binomial}(n=5, p=0.5)$\n",
    "    - $f=1$\n",
    "\n",
    "$$\\begin{align}\n",
    "    C_X(s,t) &= Cov[X(s), X(t)] \\\\\n",
    "    &= Cov[A \\cos (2 \\pi f s), A \\cos (2 \\pi f t)] \\\\\n",
    "    &= \\cos (2 \\pi f s) \\cdot \\cos (2 \\pi f t) \\cdot Cov[A , A] \\\\\n",
    "    &= \\cos (2 \\pi f s) \\cdot \\cos (2 \\pi f t) \\cdot Var[A] \\\\\n",
    "    &= \\cos (2 \\pi f s) \\cdot \\cos (2 \\pi f t) \\cdot np(1-p) \\\\\n",
    "    &= 1.25 \\cdot \\cos (2 \\pi f s) \\cdot \\cos (2 \\pi f t)\n",
    "\\end{align}$$\n",
    "\n",
    "- We can check that this is correct by seeing if we get the variance function $V(t)$ from $C_X(s,t)$ when $s=t$\n",
    "\n",
    "$$\\begin{align}\n",
    "    C_X(t,t) &= 1.25 \\cdot \\cos (2 \\pi f t) \\cdot \\cos (2 \\pi f t) \\\\\n",
    "    &= 1.25 \\cdot \\cos^2 (2 \\pi f t) \\\\\n",
    "    &= V(t)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 52.2 (Poisson Process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consider the Poisson process $\\{ N(t); t \\ge 0 \\}$ of rate $\\lambda$ defined in example 47.1. Recall that $N(t)$ represents the number of arrivals on the interval $(0,t)$, which (by properties of the Poisson process) follows a $\\text{Poisson}(\\mu=\\lambda t)$ distribution. What is the autocovariance of this process $Cov[N(s), N(t)]$\n",
    "\n",
    "- To do this, let's assume (without loss of generality) that $0 \\lt s \\lt t \\lt \\inf$\n",
    "    - We know that $N(t)$ of a Poisson process is independent for non-overlapping time periods\n",
    "    - Since $s$ and $t$ are overlapping and $t > s$, let's rewrite $t$ as 2 non-overlapping time periods\n",
    "        - $t = s + (t-s)$   \n",
    "\n",
    "$$\\begin{align}\n",
    "    Cov[N(s), N(t)] &= Cov[N(s), N(s) + N(t-s)] \\\\\n",
    "    &= Cov[N(s), N(s)] + Cov[N(s), N(t-s)] \\\\\n",
    "    &= Cov[N(s), N(s)] & \\text{by independence of non-overlapping time periods } Cov[N(s), N(t-s)] = 0 \\\\\n",
    "    &= Var[N(s)] \\\\\n",
    "    &= \\lambda \\cdot s\n",
    "\\end{align}$$\n",
    "\n",
    "- So generally, the autocovariance function of a Poisson process $$ C_N(s,t) = \\lambda \\cdot \\text{min}(s,t) $$\n",
    "\n",
    "- Again, we can sanity check the case where $s=t$, to see if we get the variance of $N(t)$\n",
    "    - $C_N(t,t) = \\lambda \\cdot \\text{min}(t,t) = \\lambda \\cdot t = V(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 52.3 (White Noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consider the white noise process $\\{ Z[n] \\}$ defined in example 47.2, which is simply IID random variables. What is the autocovariance function?\n",
    "    - That is, $X[n] = Z[n]$, where $Z[n] \\sim \\text{some i.i.d process}$\n",
    "    - $Var[Z[n]] = \\sigma^2$\n",
    "\n",
    "- Since each observation $Z[n]$ is IID from standard normal distribution, \n",
    "    - $C_Z(n) = \\begin{Bmatrix} Cov[Z[n], Z[m]] = 0 & \\text{when } n \\neq m \\\\ Cov[Z[n], Z[m]] = \\sigma^2 & \\text{when } n = m \\end{Bmatrix}$\n",
    "\n",
    "- For convenience, let's define a discrete delta function $\\delta[k] = \\begin{Bmatrix} 1 & k=0 \\\\ 0 & k \\neq 0 \\end{Bmatrix}$ \n",
    "    - Writing the covariance function in terms of $\\delta[k]$ will let us express covariance across multiple time steps more cleanly\n",
    "    - $$ C_Z[m,n] = \\sigma^2 \\delta[m-n] $$\n",
    "\n",
    "- Let's check if we can derive the white noise variance functino from the autocovariance function\n",
    "    - $$C_Z[m,m] = \\sigma^2 \\delta[m-m] = \\sigma^2 \\delta[0] = \\sigma^2 = V[n]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 52.4 (Random Walk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consider the random walk process $\\{ X[n]; n \\ge 0 \\}$ from example 47.3. Recall that random walk means that $$X[n] = X[n-1] + Z[n] = X[n-2] + Z[n-1] + Z[n] = Z[0] + ... Z[n]$$. What is the autocovariance function?\n",
    "\n",
    "- Let's assume (without loss of generality) $0 \\lt m \\lt n \\lt \\inf$\n",
    "\n",
    "$$\\begin{align}\n",
    "    C_X[m,n] &= Cov[X[m], X[n]] \\\\\n",
    "    &= Cov[Z[1] + Z[2] + ... Z[m], Z[1] + Z[2] + ... Z[n]] \\\\\n",
    "    &= \\sum_{i=j}^{i=m} Cov[Z[i], Z[j]] + \\sum_{i \\neq j} Cov[Z[i], Z[j]] \\\\\n",
    "    &= \\sum_{i=j}^{i=m} Cov[Z[i], Z[j]] \\\\\n",
    "    &= m \\cdot Var[Z[1]] \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "- In other words, $C_X[m,n] = \\text{min}(m,n) Var[Z[1]]$\n",
    "\n",
    "- Sanity check against known result $Var[m,n]$\n",
    "    - $C_X[m,m] = \\text{min}(m,m) Var[Z[1]] = m \\cdot Var[Z[1]] = V[m]$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
